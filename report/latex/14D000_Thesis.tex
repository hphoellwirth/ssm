\documentclass[11pt, oneside]{scrreprt}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{bm}
\usepackage{subcaption}
%\usepackage{algorithm2e}
%\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{graphicx}
\graphicspath{ {images/} }

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

%%%%%%%%
%    Cover     %
%%%%%%%%
\title{\textit{}\\\textit{}\\State Space Models}
\author{Hans-Peter H{\"o}llwirth}
\publishers{Master Project Report \\ 
Barcelona Graduate School of Economics \\ Master Degree in Data Science \\ 2017}
\date{}

\begin{document}
\maketitle
%\afterpage{\blankpage}

%%%%%%%%%%%%%
%    Table of Contents   %
%%%%%%%%%%%%%
\newpage
\tableofcontents
\newpage

%%%%%%%%%%
%    Introduction   %
%%%%%%%%%%
\chapter{Introduction}
\label{chp:introduction}



%%%%%%%%
%    Models   %
%%%%%%%%
\chapter{State Space Models}
\label{chp:models}
State space models consist of two set of data:
\begin{enumerate}
	\item A series of \textbf{latent states} $\{x_t\}_{t=1}^T$ (with $x_t \in \mathcal{X}$) that forms a Markov chain. Thus, $x_t$ is independent of all past states but $x_{t-1}$.
	\item A set of \textbf{observations} $\{y_t\}_{t=1}^T$ (with $y_t \in \mathcal{Y}$) where any observation $y_t$ only depends on its latent state $x_t$. In other words, an observation is a noisy representation of its underlying state.
\end{enumerate}
Note that if the state space $\mathcal{X}$ and the observation state $\mathcal{Y}$ are both discrete sets, the state space model reduces to a Hidden Markov Model.\\

The relation between the latent states and observations can be summarized by two probability distributions:
\begin{enumerate}
	\item The \textbf{transition density} from the current state to a new state $p(x_{t+1} | x_t, \boldsymbol{\theta})$.
	\item The \textbf{measurement density} for an observation given the latent state $p(y_t | x_t, \boldsymbol{\theta})$.
\end{enumerate}
Here, $\boldsymbol{\theta} \in \Theta$ denotes the parameter vector of a state space model. 


%%%%  Local Level Model  %%%%
\section{Local Level Model}
% replace a and P with mu and Sigma
Arguably, the simplest state space model is the (univariate) local level model. It has the following form:

\begin{center}
\begin{tabular}{ r r l }
  observation: & $y_t = x_t + \epsilon_t$, & $\epsilon_t \sim N(0,\sigma_{\epsilon}^2)$ \\
  state: & $x_{t+1} = x_t + \eta_t$, & $\eta_t \sim N(0,\sigma_{\eta}^2)$ \\
\end{tabular}
\end{center}
\bigskip
with some initial state $x_1 \sim N(a_1, P_1)$. All noise elements, i.e. all $\epsilon_t$'s and $\eta_t$'s, are both mutually independent and independent from the initial state $x_1$. Assuming that we know $a_1$ and $P_1$, the model is fully specified by the following vector of parameters:
$$
\boldsymbol{\theta} = [\sigma_{\eta}^2,  \sigma_{\epsilon}^2]^T
$$
Note that in the case of noise-free observations (i.e. $\sigma_{\eta}^2 = 0$), the model reduces to a pure random-walk. Likewise, if $\sigma_{\epsilon}^2 = 0$, the observations $\{y_t\}_{t=1}^T$ are a white noise representation of a some value $x_1$.\\
The transition and measurement density of the local level model are simple to deduce:
\begin{center}
\begin{tabular}{ r l }
  $p(x_{t+1} | x_t, \boldsymbol{\theta})$ & $\sim N(x_t,\sigma_{\epsilon}^2)$ \\
  $p(y_t | x_t, \boldsymbol{\theta})$ & $\sim N(x_t,\sigma_{\eta}^2)$ \\
\end{tabular}
\end{center}
\bigskip

%%%%  Latent State Inference  %%%%
\section{Latent State Inference}
Often, the main objective in state space models is to infer the latent state from observations. Let $\mathcal{I}_t$ denote the set of observed values up to time $t$:
$$
\mathcal{I}_t = \{y_1, y_2, \ldots, y_t\}
$$ 
Then information about the latent state $x_t$ can be summarized by the following two probability distributions:
\begin{enumerate}
	\item The \textbf{prediction density}, $p(x_{t} | \mathcal{I}_{t-1}, \boldsymbol{\theta})$, gives the probability of $x_t$ given past observations  $\mathcal{I}_{t-1}$.
	\item The \textbf{filtering density}, $p(x_{t} | \mathcal{I}_{t}, \boldsymbol{\theta})$, gives the probability of $x_t$ given the current and past observations  $\mathcal{I}_{t}$.
\end{enumerate}	
The prediction and filtering densities are recursively related. Given the filtering density for state $x_{t-1}$, the prediction density for state $x_t$ is
$$
p(x_{t} | \mathcal{I}_{t-1}, \boldsymbol{\theta}) = \int p(x_t | x_{t-1}, \boldsymbol{\theta}) p(x_{t-1} | \mathcal{I}_{t-1}, \boldsymbol{\theta}) dx_{t-1}
$$
where the first term in the integral is the transition density from $x_{t-1}$ to $x_t$, and the second term is the filtering density from before. Likewise, given the prediction density for state $x_t$, the filtering density for $x_t$ is
$$
p(x_{t} | \mathcal{I}_{t}, \boldsymbol{\theta}) = \int p(x_t | x_{t-1}, \boldsymbol{\theta}) p(x_{t-1} | \mathcal{I}_{t-1}, \boldsymbol{\theta}) dx_{t-1}
$$

%%%%  Parameter Inference  %%%%
\section{Parameter Inference}
Assuming a particular state space model, another common objective is is to infer the model parameters from observations. This is usually achieved via \textbf{maximum likelihood estimation}. The log-likelihood of the observations for a given parameter vector $\boldsymbol{\theta}$ is the product of the conditional densities of observations, given all previous observations:
\begin{align} 
\begin{split}
\log \mathcal{L}(\boldsymbol{\theta}) &= \log \prod_{t=1}^T p(y_t | \mathcal{I}_{t-1}, \boldsymbol{\theta})\\
&= \sum_{t=1}^T \log  p(y_t | \mathcal{I}_{t-1}, \boldsymbol{\theta})\\
&= \sum_{t=1}^T \log  \int p(y_t | x_{t}, \boldsymbol{\theta}) p(x_{t} | \mathcal{I}_{t-1}, \boldsymbol{\theta}) d x_t\\
\end{split}					
\end{align} 
The decomposition of the observation densities into measurement density and prediction density, however, makes the maximization problem analytically intractable for most state space models.



%%%%%%%
%  Filtering %
%%%%%%%
\chapter{Filtering}
\label{chp:filtering}
% add parameter
The objective of filtering is to update our knowledge of the system each time a new observation $y_t$ is brought in. That is, we want to find an estimate of the latent process $x_{0:t}$, given all observations $\mathcal{I}_t = y_{0:t}$:
$$
x_{0:t} | \mathcal{I}_t
$$
Note that the joint distribution of the latent process conditioned on the observations can be decomposed in a recursive form:
$$
p(x_{0:t} | \mathcal{I}_t) = \Big[ \frac{p(y_t | x_t) p(x_t | x_{t-1})}{p(y_t | \mathcal{I}_{t-1})} \Big] p(x_{0:(t-1)} | \mathcal{I}_{t-1)} 
$$
This form allows for updating our knowledge of the system in an online fashion. This has significant computational advantages: We do not need to keep the whole time series in memory and we can simply update our knowledge once we observe a new $y_t$. Unfortunately, in many state space models the normalization term $p(y_t | \mathcal{I}_{t-1})$ is analytically intractable. One notable exception are linear Gaussian state space models such as the local level model.

%%%%  Kalman Filter   %%%%
\section{Kalman Filter}
State space models in which both the latent states $\{x_t\}_{t=1}^T$ and the observations $\{y_t\}_{t=1}^T$ have linear dependencies and are normally distributed, the joint distribution and of the latent process $p(x_{0:t} | y_{0:t})$ is also Gaussian (and so are the prediction and filtering density). 
The inference problem can be analytically solved by using standard results of multivariate Gaussian marginal and conditional distributions.\\

The Kalman filter, however, uses a more efficient way to infer the latent states. 
The filter recursively computes the Gaussian prediction density $p(x_{t} | \mathcal{I}_{t-1}, \boldsymbol{\theta}) = N(\mu_{t | t-1}, \Sigma_{t | t-1})$ and filtering density $p(x_{t} | \mathcal{I}_{t}, \boldsymbol{\theta}) = N(\mu_{t | t}, \Sigma_{t | t})$ by obtaining their respective mean and covariance. 
This method has the big advantage that it does not need all observations to be kept in memory and can easily update the system whenever a new observation is made.
Consider the multivariate generalization of the univariate local level model from before:
\bigskip
\begin{center}
\begin{tabular}{ r r l }
  observation: & $\boldsymbol{y}_t = \boldsymbol{x}_t + \boldsymbol{\epsilon}_t$, & $\boldsymbol{\epsilon}_t \sim N(\textbf{0}, \Sigma_{\epsilon})$ \\
  state: & $\boldsymbol{x}_{t+1} = \boldsymbol{x}_t + \boldsymbol{\eta}_t$, & $\boldsymbol{\eta}_t \sim N(\textbf{0}, \Sigma_{\eta})$ \\
\end{tabular}
\end{center}
\bigskip
For the case of this model, the mean and (co)variance of the prediction and filtering density are updated as follows:
\begin{enumerate}
	\item The \textbf{prediction step} obtains the \textit{a priori} estimate of $\boldsymbol{x}_t$, given $\mathcal{I}_{t-1}$ (using the \textit{a posteriori} estimate with $t-1$).
		\begin{align} 
		\begin{split}
		\boldsymbol{\mu}_{t | t-1} &= \boldsymbol{\mu}_{t-1 | t-1}\\
		\Sigma_{t | t-1} &= \Sigma_{t-1 | t-1} + \Sigma_{\eta}\\
		\end{split}					
		\end{align} 
	\item The \textbf{update step} combines a new observation $\boldsymbol{y}_t$ with the \textit{a priori} estimate to obtain an improved \textit{a posteriori} estimate. 
		\begin{align} 
		\begin{split}
		\boldsymbol{\mu}_{t | t} &= \boldsymbol{\mu}_{t | t-1} + K_t \boldsymbol{v}_t\\
		\Sigma_{t | t} &= \Sigma_{t | t-1}(1 - K_t)\\
		\end{split}					
		\end{align} 
		where $\boldsymbol{v}_t = \boldsymbol{y}_t - \boldsymbol{\mu}_{t | t-1}$ denotes the difference between prediction and observation and $K_t = \Sigma_{t | t-1} (\Sigma_{t | t-1} + \Sigma_{\epsilon})^{-1}$ denotes the \textit{Kalman gain}. It determines how much the new observation affects the updated prediction.	
\end{enumerate}
Note that to start the recursion, we need an initial state density with $\boldsymbol{\mu}_1$ and $\Sigma_1$.

\subsection{Algorithm}
In the following version of the algorithm we assume $\boldsymbol{\mu}_1$ and $\Sigma_1$ to be known. There are various ways to initialize the algorithm when $\boldsymbol{\mu}_1$ and $\Sigma_1$ are unknown, however, these methods are beyond the scope of this project.
%The filter is a recursive algorithm. The current best estimate is updated whenever a new observation is obtained. To start the recursion, we need an initial state which is drawn with $a_1$ and $P_1$. We assume $a_1$ and $P_1$ to be known. There are various ways to initialize the algorithm when $a_1$ and $P_1$ are unknown, however, these methods are beyond the scope of this project.

\begin{algorithm}
\caption{(Local Level) Kalman filter}
\label{alg:kalman}
  \begin{algorithmic}[1]
    \Procedure{KalmanFilter}{$\mathcal{I}_T, \boldsymbol{\theta}, \boldsymbol{\mu}_1,\Sigma_1$}
      \State $\boldsymbol{\mu}_{1 | 0}\gets \boldsymbol{\mu}_1$\Comment{initialization}
      \State $\Sigma_{1 | 0}\gets \Sigma_1$
      \smallskip
      \For{\texttt{$t$ in $1:T$}}
      	\State $\boldsymbol{v}_t = \boldsymbol{y}_t - \boldsymbol{\mu}_{t | t-1}$
      	\State $K_t = \Sigma_{t | t-1} (\Sigma_{t | t-1} + \Sigma_{\epsilon})^{-1}$
	\smallskip
      	\State $\boldsymbol{\mu}_{t | t} = \boldsymbol{\mu}_{t | t-1} + K_t \boldsymbol{v}_t$\Comment{update step}
      	\State $\Sigma_{t | t} = \Sigma_{t | t-1}(1 - K_t)$
	\smallskip
      	\State $\boldsymbol{\mu}_{t+1 | t}\gets \boldsymbol{\mu}_{t | t}$\Comment{prediction step}
      	\State $\Sigma_{t+1 | t}\gets \Sigma_{t | t} + \Sigma_{\eta}$
      \EndFor
      \State \textbf{return} $\{\boldsymbol{\mu}_{t | t}\}$, $\{\Sigma_{t | t}\}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
\textit{Algorithm \ref{alg:kalman}} describes the recursive update of the prediction and filtering density.  For our purpose, the algorithm returns the filtering densities. 
The sequence of filtering means $\{\boldsymbol{\mu}_{t | t}\}$ is the best possible prediction for the latent states $\{\boldsymbol{x}_t\}$. 
The sequence of covariances $\{\Sigma_{t | t}\}$ can be used to obtain confidence intervals for these estimates. \\  

Note that the algorithm needs to invert the matrix $F_t = \Sigma_{t | t-1} + \Sigma_{\epsilon}$ at each iteration. For large dimensions of the states/observations, this can slow down this version of the Kalman filter significantly.

\subsection{Likelihood evaluation}
The log-likelihood function for the linear Gaussian space model has the following (\textit{prediction error decomposition}) form:
$$
\log \mathcal{L}(\mathcal{I}_T, \boldsymbol{\theta}) = -\frac{Td}{2} \log(2 \pi) - \frac{1}{2} \sum_{t=1}^T (\log |F_t| + v_t^TF_t^{-1} v_t)
$$
Its elements $F_t$ and $v_t$ are routinely calculated by the Kalman filter and so the log-likelihood can be directly evaluated in the Kalman function. Note that $F_t$ might not be singular for all $t=1,\ldots, T$ for particular $\boldsymbol{\theta}$ values. Setting $\log \mathcal{L}(\mathcal{I}_T, \boldsymbol{\theta}) = -\infty$ in this case suffices for the purpose of maximum likelihood estimation.

\subsection{Example}
% local level example plotting both prediction and confidence level

%%%%  Particle Filter   %%%%
\section{Particle Filter}
If the state space model is not linear and Gaussian, both the joint distribution $p(x_{0:t} | \mathcal{I}_t)$ and the marginal distribution $p(x_{t} | \mathcal{I}_t)$ are usually not analytically solvable due to the intractability of the normalization constant $p(y_t | \mathcal{I}_{t-1})$. In this case we can only resort to sampling techniques to approximate these distribution densities. \\

\textit{Particle filtering} methods (constituting a sub-class of \textit{Sequential Monto Carlo} methods) approximate the prediction density $p(x_{t} | \mathcal{I}_{t-1}, \boldsymbol{\theta})$ and filtering density $p(x_{t} | \mathcal{I}_{t}, \boldsymbol{\theta})$ sequentially by using importance sampling techniques. There exist many different method variants, all of which involve two basic steps: simulating from the transition density $p(x_{t+1} | x_t, \boldsymbol{\theta})$ and evaluating the measurement density $p(y_t | x_t, \boldsymbol{\theta})$. 

\subsection{Sequential Importance Resampling (SIR)}
One of the best-known particle filter methods is the \textit{Sequential Importance Resampling (SIR)} algorithm by Gordon et al. (1993). Let $P$ be the number of particles (= samples) per state. The algorithm recursively computes prediction and filtering particles:
\begin{enumerate}
	\item The \textbf{prediction step} obtains a new prediction particle for each filtering particle by propagating the system, using the transition density:
	$$
	x_{t | t-1}^i \sim p(x_t | x_{t-1 | t-1}^i, \theta) \quad \text{for } i=1, \ldots, P
	$$
	\item The \textbf{filtering step} (or update step) computes the importance weight $w_t^i$ of each prediction particle 
	$$
	w_{t}^i = \frac{p(y_t | x_{t | t-1}^i, \theta)}{\sum_{j=1}^P p(y_t | x_{t | t-1}^j, \theta)} \quad \text{for } i=1, \ldots, P
	$$
	and then picks the filtering particles via multinomial sampling, using the computed importance weights as respective probabilities:	
	$$
	x_{t | t }^j \sim MN(w_t^1, \ldots, w_t^P) \quad \text{for } j=1, \ldots, P
	$$
\end{enumerate}
The algorithm's main characteristic is the resampling within the filtering step which removes particles with small weights with high probability while likely copying particles with high weights multiple times. While this step increases the immediate Monte Carlo variance, it gives better stability for future steps by reducing the risk of weight degeneracy (Doucet and Johansen, 2008). 


\subsection{Algorithm}

\begin{algorithm}
\caption{(Local Level) Particle filter}
\label{alg:particle}
  \begin{algorithmic}[1]
    \Procedure{ParticleFilter}{$\mathcal{I}_T, \boldsymbol{\theta}, \boldsymbol{\mu}_1,\Sigma_1$}
      \State $\boldsymbol{\mu}_{1 | 0}\gets \boldsymbol{\mu}_1$\Comment{initialization}
      \State $\Sigma_{1 | 0}\gets \Sigma_1$
      \smallskip
      \For{\texttt{$t$ in $1:T$}}
      	\State $\boldsymbol{v}_t = \boldsymbol{y}_t - \boldsymbol{\mu}_{t | t-1}$
      	\State $K_t = \Sigma_{t | t-1} (\Sigma_{t | t-1} + \Sigma_{\epsilon})^{-1}$
	\smallskip
      	\State $\boldsymbol{\mu}_{t | t} = \boldsymbol{\mu}_{t | t-1} + K_t \boldsymbol{v}_t$\Comment{update step}
      	\State $\Sigma_{t | t} = \Sigma_{t | t-1}(1 - K_t)$
	\smallskip
      	\State $\boldsymbol{\mu}_{t+1 | t}\gets \boldsymbol{\mu}_{t | t}$\Comment{prediction step}
      	\State $\Sigma_{t+1 | t}\gets \Sigma_{t | t} + \Sigma_{\eta}$
      \EndFor
      \State \textbf{return} $\{\boldsymbol{\mu}_{t | t}\}$, $\{\Sigma_{t | t}\}$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}


\subsection{Likelihood evaluation}
The likelihood 

%%%%  Importance Sampling Particle Filter   %%%%
\section{Importance Sampling Particle Filter}


%%%%%%%%
%  Illustration %
%%%%%%%%
\chapter{Illustration}
\label{chp:Illustration}


%%%%  Trivariate Local Level Model  %%%%
\section{Trivariate Local Level Model}

\subsection{The Model}
Consider a time series of length $T$ with each observation $\boldsymbol{y}_t=[y_{1t}, y_{2t}, y_{3t}]^T$ and each state $\boldsymbol{x}_t=[x_{1t}, x_{2t}, x_{3t}]^T$ being described by a 3-dimensional vector.

\bigskip
\begin{center}
\begin{tabular}{ r r l }
  observation: & $\boldsymbol{y}_t = \boldsymbol{x}_t + \boldsymbol{\epsilon}_t$, & $\boldsymbol{\epsilon}_t \sim N(\textbf{0}, \sigma_{\epsilon}^2 I_3)$ \\
  state: & $\boldsymbol{x}_{t+1} = \boldsymbol{x}_t + \boldsymbol{\eta}_t$, & $\boldsymbol{\eta}_t \sim N(\textbf{0}, \Sigma_{\eta})$ \\
\end{tabular}
\end{center}
\bigskip
with initial state $\boldsymbol{x}_1 \sim N(\boldsymbol{a}_1, P_1)$ and where we restrict the covariance matrix of the state disturbances, $\Sigma_{\eta}$, to the form
$$
\Sigma_{\eta} = 
\begin{bmatrix}
\sigma_{\eta 1}^2 & \rho \sigma_{\eta 1} \sigma_{\eta 2} & \rho \sigma_{\eta 1} \sigma_{\eta 3}
\\ \rho \sigma_{\eta 1} \sigma_{\eta 2} & \sigma_{\eta 2}^2 & \rho \sigma_{\eta 2} \sigma_{\eta 3}
\\ \rho \sigma_{\eta 1} \sigma_{\eta 3} & \rho \sigma_{\eta 2} \sigma_{\eta 3} & \sigma_{\eta 3}^2
\end{bmatrix}
$$
Thus, $\Sigma_{\eta}$ can be described by $\sigma_{\eta 1}^2$, $\sigma_{\eta 2}^2$, $\sigma_{\eta 3}^2 > 0$ and $\rho \in [0,1]$. Furthermore, we assume for simplicity that the observation noise has the same variance in each dimension $\sigma_{\epsilon}^2 > 0$. Therefore, the model is fully specified by the following vector of parameters:
$$
\boldsymbol{\theta} = [\rho, \sigma_{\eta 1}^2, \sigma_{\eta 2}^2, \sigma_{\eta 3}^2, \sigma_{\epsilon}^2]^T
$$
The initial state parameters $\boldsymbol{a}_1$ and $P_1$ are assumed to be known.

\subsection{Realization}
\textit{Figure \ref{fig:mllm_realization}} plots the states and observations for a realization of the trivariate local level model with length $T=100$. The model parameters are 
$$
\boldsymbol{\theta} = [\rho = 0.7, \sigma_{\eta 1}^2 = 4.2, \sigma_{\eta 2}^2 = 2.8, \sigma_{\eta 3}^2 = 0.9, \sigma_{\epsilon}^2 = 1.0]^T
$$
The initial state $x_1$ is drawn from a standard normal.

\begin{figure}[h!]
\centering
\includegraphics[width=115mm]{../../images/mllm-realization.png}
\caption{Realization of the model with $T=100$}
\label{fig:mllm_realization}
\end{figure}




%%%%  Hierarchical Dynamic Poisson Model   %%%%
\newpage
\section{Hierarchical Dynamic Poisson Model}
Explain the main idea and potential use cases.

\subsection{The Model}
Consider a time series over $M$ days, each consisting of $N$ intra-daily observations. 
Let $m$ denote the day and $n$ be the intraday index.

\bigskip
\begin{center}
\begin{tabular}{ r r l }
  observation: & $y_{mn}$ & $= \text{Poisson}(\lambda_{mn})$\\
  state: & $\log \lambda_{mn}$ & $= \log \lambda_m^{(D)} + \log \lambda_{mn}^{(I)} + \log \lambda_n^{(P)}$\\  
\end{tabular}
\end{center}
\bigskip
where the state consists of a daily, an intra-daily, and a periodic component:
\bigskip
\begin{center}
\begin{tabular}{ r l l }
  daily component: & $\log \lambda_{m+1}^{(D)} = \phi_0^{(D)} + \phi_1^{(D)} \log \lambda_{m}^{(D)}  + \eta_m^{(D)}$ & $\eta_t \sim N(0, \sigma^2_{(D)})$ \\
  intra-daily component: & $\log \lambda_{mn+1}^{(I)} = \phi_1^{(I)} \log \lambda_{mn}^{(I)}  + \eta_{mn}^{(I)}$ & $\eta_{mn} \sim N(0, \sigma^2_{(I)})$ \\
    periodic component: & $\log \lambda_n^{(P)} = \phi_1^{(P)} \sin(\pi (n-1)/M)$ &\\
\end{tabular}
\end{center}
\bigskip
The initial daily and intra-daily component is drawn from a normal with mean $a_1$ and covariance $P_1$: 
$$\log \lambda_{1}^{(D)}, \log \lambda_{1}^{(I)}  \sim N(a_1, P_1)$$ 
Note that both the daily and intra-daily component constitute an AR(1) model, with the mean of the intra-daily component $\phi_0^{(I)}$ set to 0. 
The model is fully specified by the following vector of parameters:
$$
\boldsymbol{\theta} = [ \phi_0^{(D)},  \phi_1^{(D)}, \sigma^2_{(D)}, \phi_1^{(I)}, \sigma^2_{(I)}, \phi_1^{(P)}]^T
$$
Again, the initial state parameters $a_1$ and $P_1$ are assumed to be known.


\subsection{Realization}
\textit{Figure \ref{fig:hdpm_realization}} plots the states and observations for a realization of the hierarchical dyanmic Poisson model over $N=5$ days with $M=20$ intra-daily observations. The model parameters are 
$$
\boldsymbol{\theta} = [ \phi_0^{(D)} = 0.7,  \phi_1^{(D)} = 0.6, \sigma^2_{(D)} = 0.6, \phi_1^{(I)} = 0.3, \sigma^2_{(I)} = 0.2, \phi_1^{(P)} = 0.8]^T
$$
The initial daily and intra-daily state components were drawn from a standard normal.

\begin{figure}[h!]
\centering
\includegraphics[width=115mm]{../../images/hdpm-realization.png}
\caption{Realization of the model with $N=5$ and $M=20$}
\label{fig:hdpm_realization}
\end{figure}


\subsection{Densities}
State transition and prediction density and how they are used in the particle filter

\subsection{Maximum Likelihood Estimation}
Show log-likelihood plots

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=70mm]{../../images/hdpm-loglik-Dphi0.png}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=70mm]{../../images/hdpm-loglik-Dphi1.png}
\end{subfigure}
\caption{Belief convergence without misinformation after 300 and 2000 iterations}
\label{fig:conv_nomisinfo}
\end{figure}

%%%%%%%%%%
%    Evaluation   %
%%%%%%%%%%
\chapter{Evaluation}
\label{chp:evaluation}
Particle filtering suffers from propagation error.
Current approximations errors are related to past approximation errors. 
The number of particles $P$ should increase with the sample size $T$ to guarantee a good degree of approximation.

%%%%%%%%%%
%    Conclusion   %
%%%%%%%%%%
\chapter{Conclusion}
\label{chp:conclusion}
by Etessami et al.\cite{etessami2014_2}

%%%%%%%%%%%
%    Bibliography          %
%%%%%%%%%%%
%\afterpage{\blankpage}
\bibliography{references}
\bibliographystyle{plain}
\end{document}  















